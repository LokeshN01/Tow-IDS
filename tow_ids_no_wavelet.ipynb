{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb20550-9f11-4cab-bdeb-3d2da39e2988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 19s 952ms/step - loss: 0.5870 - accuracy: 0.8622 - val_loss: 0.4712 - val_accuracy: 0.8516\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 15s 917ms/step - loss: 0.3765 - accuracy: 0.8839 - val_loss: 0.4240 - val_accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 15s 914ms/step - loss: 0.2836 - accuracy: 0.8839 - val_loss: 0.4216 - val_accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 15s 923ms/step - loss: 0.1559 - accuracy: 0.8839 - val_loss: 0.7260 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 15s 920ms/step - loss: 0.0998 - accuracy: 0.9114 - val_loss: 1.0838 - val_accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 15s 921ms/step - loss: 0.0766 - accuracy: 0.9921 - val_loss: 1.3279 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 15s 920ms/step - loss: 0.0330 - accuracy: 0.9980 - val_loss: 1.4648 - val_accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 15s 925ms/step - loss: 0.0395 - accuracy: 0.9902 - val_loss: 1.5090 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14f354631850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Conv Block A, added L2 regularization\n",
    "def conv_block_a(filters, input_shape=None):\n",
    "    layers = [\n",
    "        SeparableConv2D(filters, kernel_size=3, strides=3, activation='relu', padding='same', input_shape=input_shape, kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.3)  # Add dropout here as well\n",
    "    ]\n",
    "    block = Sequential(layers)\n",
    "    return block\n",
    "\n",
    "# Conv Block B, added dropout\n",
    "def conv_block_b(filters):\n",
    "    block = Sequential([\n",
    "        SeparableConv2D(filters, kernel_size=3, strides=3, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3)  \n",
    "    ])\n",
    "    return block\n",
    "\n",
    "# Conv Block C\n",
    "def conv_block_c():\n",
    "    block = Sequential([\n",
    "        SeparableConv2D(512, kernel_size=3, strides=3, activation='relu', padding='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    return block\n",
    "\n",
    "# Load your normalized data\n",
    "X = np.load('normalized_packet_data/452x452_normalized.npy')  \n",
    "\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "\n",
    "# Load labels and convert them to integers\n",
    "labels_df = pd.read_csv('labels/452x452.csv')  \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels_df['Label'].values)\n",
    "y = to_categorical(integer_encoded)\n",
    "\n",
    "# Define input shape based on X\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "# Building the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding Conv Block A with input shape\n",
    "model.add(conv_block_a(256, input_shape=input_shape))\n",
    "\n",
    "# Adding 5 Conv Block B\n",
    "for _ in range(5):\n",
    "    model.add(conv_block_b(256))\n",
    "\n",
    "# Adding Conv Block C\n",
    "model.add(conv_block_c())\n",
    "\n",
    "# Compiling the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with Early Stopping\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e91a9c-a926-44f0-a0e1-fdba5b183162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_19 (Sequential)  (None, 75, 75, 256)       1545      \n",
      "                                                                 \n",
      " sequential_20 (Sequential)  (None, 25, 25, 256)       69120     \n",
      "                                                                 \n",
      " sequential_21 (Sequential)  (None, 9, 9, 256)         69120     \n",
      "                                                                 \n",
      " sequential_22 (Sequential)  (None, 3, 3, 256)         69120     \n",
      "                                                                 \n",
      " sequential_23 (Sequential)  (None, 1, 1, 256)         69120     \n",
      "                                                                 \n",
      " sequential_24 (Sequential)  (None, 1, 1, 256)         69120     \n",
      "                                                                 \n",
      " sequential_25 (Sequential)  (None, 2)                 281794    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 628939 (2.40 MB)\n",
      "Trainable params: 625867 (2.39 MB)\n",
      "Non-trainable params: 3072 (12.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc147d3a-e0da-4be7-aa99-45b386e2f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/452x452_tow-ids_model_no_wavelet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnagana/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory to save the model\n",
    "model_dir = 'models'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the model\n",
    "model_save_path = 'models/452x452_tow-ids_model_no_wavelet.h5'\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save(model_save_path, save_format='h5')\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34bff3f3-2f62-4a7c-98e8-f5bc850fa07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 190ms/step\n",
      "Predicted Class: Normal\n",
      "True Class: Normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load('normalized_packet_data/452x452_normalized.npy')\n",
    "labels_df = pd.read_csv('labels/452x452.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels_df['Label'].values)\n",
    "test_labels = to_categorical(integer_encoded)\n",
    "\n",
    "sample_data = test_data[240] \n",
    "sample_data = np.expand_dims(X, axis=-1)\n",
    "sample_label = test_labels[240]\n",
    "\n",
    "# Make prediction\n",
    "sample_prediction = model.predict(sample_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_class = np.argmax(sample_prediction, axis=1)\n",
    "true_class = np.argmax(sample_label)  # No need to use axis=1 here as it's a single label\n",
    "\n",
    "# Assuming label_encoder is a fitted LabelEncoder instance\n",
    "predicted_class_label = label_encoder.inverse_transform(predicted_class)[0]\n",
    "true_class_label = label_encoder.inverse_transform([true_class])[0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class_label}\")\n",
    "print(f\"True Class: {true_class_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca6d48-b8f5-4aba-a123-d8204c5d7d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
