{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a2efe0-c259-42e8-92e9-4e7d15708ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "\n",
    "# Conv Block A\n",
    "def conv_block_a(filters, input_shape=None):\n",
    "    layers = [\n",
    "        SeparableConv2D(filters, kernel_size=3, strides=3, activation='relu', padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2))\n",
    "    ]\n",
    "    block = Sequential(layers)\n",
    "    return block\n",
    "\n",
    "# Conv Block B\n",
    "def conv_block_b(filters):\n",
    "    block = Sequential([\n",
    "        SeparableConv2D(filters, kernel_size=3, strides=3, activation='relu', padding='same'),\n",
    "        BatchNormalization()\n",
    "    ])\n",
    "    return block\n",
    "\n",
    "# Conv Block C\n",
    "def conv_block_c():\n",
    "    block = Sequential([\n",
    "        SeparableConv2D(512, kernel_size=3, strides=3, activation='relu', padding='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55208805-aca2-4167-8294-c45cc6885326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 38, 38, 256)       2075      \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 13, 13, 256)       69120     \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 5, 5, 256)         69120     \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 2, 2, 256)         69120     \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 1, 1, 256)         69120     \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 1, 1, 256)         69120     \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 2)                 281794    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 629469 (2.40 MB)\n",
      "Trainable params: 626397 (2.39 MB)\n",
      "Non-trainable params: 3072 (12.00 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 7s 262ms/step - loss: 0.5840 - accuracy: 0.8543 - val_loss: 0.4578 - val_accuracy: 0.8516\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.1550 - accuracy: 0.8839 - val_loss: 0.9186 - val_accuracy: 0.8516\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.0814 - accuracy: 0.9528 - val_loss: 1.4053 - val_accuracy: 0.8516\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0475 - accuracy: 0.9980 - val_loss: 1.5955 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.0363 - accuracy: 0.9921 - val_loss: 1.6995 - val_accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.0317 - accuracy: 0.9941 - val_loss: 1.6428 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0491 - accuracy: 0.9921 - val_loss: 1.4578 - val_accuracy: 0.8516\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.2701 - val_accuracy: 0.8516\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0596 - accuracy: 0.9823 - val_loss: 1.1704 - val_accuracy: 0.8516\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0201 - accuracy: 0.9921 - val_loss: 1.2413 - val_accuracy: 0.8516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x146a240d89a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "# Load your data\n",
    "X = np.load('wavelet_transformed_data/layered_452x452_normalized.npy')\n",
    "\n",
    "# Load labels and convert them to integers\n",
    "labels_df = pd.read_csv('labels/452x452.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels_df['Label'].values)\n",
    "y = to_categorical(integer_encoded)\n",
    "\n",
    "# Define input shape based on X\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "# Extract height, width, and channels from X.shape\n",
    "#height, width, channels = X.shape[1], X.shape[2], X.shape[3]\n",
    "\n",
    "# Define your input shape\n",
    "#input_shape = (height, width, channels)\n",
    "\n",
    "# Building the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding Conv Block A with input shape\n",
    "model.add(conv_block_a(256, input_shape=input_shape))\n",
    "\n",
    "# Adding 5 Conv Block B\n",
    "for _ in range(5):\n",
    "    model.add(conv_block_b(256))\n",
    "\n",
    "# Adding Conv Block C\n",
    "model.add(conv_block_c())\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Compiling the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bccdebe-48b5-4108-9bef-ec0d0e0da952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/452x452_tow-ids_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnagana/.local/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory to save the model\n",
    "model_dir = 'models'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Save the model\n",
    "model_save_path = 'models/452x452_tow-ids_model.h5'\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save(model_save_path, save_format='h5')\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ab241d7-a1cd-468e-8646-ddfee3dd6f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 228, 228, 3)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Predicted Class: Normal\n",
      "True Class: Normal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape sample_data to add batch dimension\n",
    "sample_data = test_data[90] \n",
    "sample_data = np.expand_dims(sample_data, axis=0)  # Reshape to (1, height, width, channels)\n",
    "sample_label = test_labels[90]\n",
    "\n",
    "# Make prediction\n",
    "sample_prediction = model.predict(sample_data)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_class = np.argmax(sample_prediction, axis=1)\n",
    "true_class = np.argmax(sample_label)  # No need to use axis=1 here as it's a single label\n",
    "\n",
    "# label_encoder is a fitted LabelEncoder instance\n",
    "predicted_class_label = label_encoder.inverse_transform(predicted_class)[0]\n",
    "true_class_label = label_encoder.inverse_transform([true_class])[0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class_label}\")\n",
    "print(f\"True Class: {true_class_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5984d0c-dffa-465d-bf08-e7d2b8132677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
